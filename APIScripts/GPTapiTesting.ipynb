{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API Key from .env file\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Configure OpenAI API client\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('testData.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "output_file_path = 'apiResponse/all_responses.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure the apiResponse directory exists\n",
    "if not os.path.exists('apiResponse'):\n",
    "    os.makedirs('apiResponse')\n",
    "\n",
    "# Example of batching\n",
    "batch_size = 3\n",
    "for i in range(0, len(data), batch_size):\n",
    "    batch = data[i:i + batch_size]\n",
    "    data_str = json.dumps(batch)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": (\n",
    "            \"I need you to scrape data from this text. List only name, index number, hobbies and social organisations. \"\n",
    "            \"Notice to list spouse's hobbies and social orgs separately. Do not list jobs, or war time occupations. \"\n",
    "            \"Do not suggest to make an algorithm. If no social orgs detected respond: - \"\n",
    "            \"Do not say anything but the asked information. \"\n",
    "            \"Response in format: \"\n",
    "            \"--\"\n",
    "            \"PersonID: \"\n",
    "            \"PersonName: \"\n",
    "            \"PersonHobbies: \"\n",
    "            \"PersonSocialOrgs: \"\n",
    "            \"SpouseID:\"\n",
    "            \"SpouseName:\"\n",
    "            \"SpouseHobbies: \"\n",
    "            \"SpouseSocialOrgs: \"\n",
    "            + data_str\n",
    "        )}\n",
    "    ]\n",
    "\n",
    "    # API call\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages,\n",
    "           temperature=0.8\n",
    "        )\n",
    "\n",
    "\n",
    "        # Ensure the 'apiResponse/raw_api_responses' directory exists\n",
    "        if not os.path.exists('apiResponse/raw_api_responses'):\n",
    "            os.makedirs('apiResponse/raw_api_responses')\n",
    "\n",
    "        # Save raw response\n",
    "        raw_response_path = f'apiResponse/raw_api_responses/raw_response_{i//batch_size}.json'\n",
    "        with open(raw_response_path, 'w', encoding='utf-8') as raw_file:\n",
    "            json.dump(response, raw_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        # Splitting on '--' to separate individual responses\n",
    "        responses = response['choices'][0]['message']['content'].split('--')[1:] \n",
    "        \n",
    "        # Storing responses along with batch and individual indexes\n",
    "        structured_responses = []\n",
    "        for j, api_response in enumerate(responses):\n",
    "            structured_responses.append({\n",
    "                \"batch_number\": i//batch_size,\n",
    "                \"person_index\": i + j,\n",
    "                \"api_response\": api_response.strip()  # Removing leading/trailing whitespaces\n",
    "            })\n",
    "\n",
    "        output_file_path = 'apiResponse/all_responses.json'\n",
    "\n",
    "        # Save/Append the batch response to the file\n",
    "        with open(output_file_path, 'a', encoding='utf-8') as file:\n",
    "            for item in structured_responses:\n",
    "                json.dump(item, file, ensure_ascii=False)\n",
    "                file.write('\\n')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in batch starting at index {i}: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert JSON Lines to standard JSON array format\n",
    "with open(output_file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "    \n",
    "with open('apiResponse/all_responses.json', 'w', encoding='utf-8') as file:\n",
    "    file.write('[' + ','.join(lines) + ']')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('apiResponse/all_responses.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "def format_api_response(data):\n",
    "    formatted_data = []\n",
    "    for item in data:\n",
    "        new_item = item.copy()\n",
    "        response = item[\"api_response\"].split(\"\\n\")\n",
    "        formatted_response = {}\n",
    "        for line in response:\n",
    "            if \": \" in line:\n",
    "                key, value = line.split(\": \", 1)\n",
    "                if \",\" in value:\n",
    "                    formatted_response[key] = [v.strip() for v in value.split(\",\")]\n",
    "                else:\n",
    "                    formatted_response[key] = value.strip()\n",
    "            else:\n",
    "                formatted_response[line] = []\n",
    "        new_item[\"api_response\"] = formatted_response\n",
    "        formatted_data.append(new_item)\n",
    "    return formatted_data\n",
    "\n",
    "formatted_data = format_api_response(data)\n",
    "formatted_json = json.dumps(formatted_data, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Example: writing formatted JSON back to a file\n",
    "with open('apiResponse/formatted_responses.json', 'w', encoding='utf-8') as file:\n",
    "    file.write(formatted_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrepancies found:\n",
      "Unexpected batch/index found: (4, 1), expected: (0, 1)\n",
      "Unexpected batch/index found: (2, 5), expected: (2, 7)\n",
      "Unexpected batch/index found: (5, 8), expected: (2, 8)\n",
      "Unexpected batch/index found: (3, 153), expected: (3, 10)\n",
      "Unexpected batch/index found: (4, 23), expected: (4, 13)\n"
     ]
    }
   ],
   "source": [
    "## index testing\n",
    "\n",
    "import json\n",
    "\n",
    "def test_ascending_indexes_and_batches(file_path):\n",
    "    # Load data from JSON file\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    expected_batch = 0\n",
    "    expected_index = 0  # expecting the first index to be 0\n",
    "    persons_in_current_batch = 0  # counter for number of persons in the current batch\n",
    "    \n",
    "    discrepancies = []  # List to hold messages about discrepancies found\n",
    "\n",
    "    for item in data:\n",
    "        current_batch = item['batch_number']\n",
    "        current_index = item['person_index']\n",
    "\n",
    "        # Check if current batch and index are as expected\n",
    "        if current_batch != expected_batch or current_index != expected_index:\n",
    "            discrepancies.append(f\"Unexpected batch/index found: ({current_batch}, {current_index}), expected: ({expected_batch}, {expected_index})\")\n",
    "        \n",
    "        # Increment expected index and persons in batch counters\n",
    "        expected_index += 1\n",
    "        persons_in_current_batch += 1\n",
    "        \n",
    "        # If three persons in the current batch have been processed,\n",
    "        # increment expected batch number and reset persons counter\n",
    "        if persons_in_current_batch == 3:\n",
    "            expected_batch += 1\n",
    "            persons_in_current_batch = 0\n",
    "    \n",
    "    # If discrepancies were found, return them, otherwise return a success message\n",
    "    if discrepancies:\n",
    "        return False, discrepancies\n",
    "    else:\n",
    "        return True, \"Indexes and batches are in order\"\n",
    "\n",
    "# Example usage:\n",
    "file_path = 'apiResponse/wrong_index_test.json'\n",
    "is_valid, message = test_ascending_indexes_and_batches(file_path)\n",
    "\n",
    "# If discrepancies were found, print them all\n",
    "if not is_valid:\n",
    "    print(\"Discrepancies found:\")\n",
    "    for msg in message:\n",
    "        print(msg)\n",
    "else:\n",
    "    print(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in index 2: Missing keywords: PersonName\n",
      "Error in index 5: Missing keywords: PersonSocialOrgs\n",
      "Error in index 9: Missing keywords: PersonID\n",
      "Error in index 12: Missing keywords: PersonSocialOrgs\n",
      "Error in index 13: Missing keywords: PersonID\n"
     ]
    }
   ],
   "source": [
    "##Right format test\n",
    "import json\n",
    "\n",
    "# List of keywords to check in 'api_response'\n",
    "keywords = [\n",
    "    \"PersonID\", \n",
    "    \"PersonName\", \n",
    "    \"PersonHobbies\", \n",
    "    \"PersonSocialOrgs\", \n",
    "    \"SpouseID\", \n",
    "    \"SpouseName\", \n",
    "    \"SpouseHobbies\", \n",
    "    \"SpouseSocialOrgs\"\n",
    "]\n",
    "\n",
    "# Read data from JSON file\n",
    "with open('apiResponse/wrong_elements_test.json', \"r\") as file:\n",
    "    persons = json.load(file)\n",
    "\n",
    "# Check each person's 'api_response' for keywords\n",
    "for person in persons:\n",
    "    api_response = person[\"api_response\"]\n",
    "    missing_keywords = []\n",
    "    \n",
    "    # Check for each keyword\n",
    "    for keyword in keywords:\n",
    "        if keyword not in api_response:\n",
    "            missing_keywords.append(keyword)\n",
    "    \n",
    "    # Report error if any keyword is missing\n",
    "    if missing_keywords:\n",
    "        print(f\"Error in index {person['person_index']}: Missing keywords: {', '.join(missing_keywords)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
