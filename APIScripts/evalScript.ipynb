{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load data from JSON\n",
    "with open('apiResponse/all_responses_200_sample.json', 'r', encoding='utf-8') as file:\n",
    "    api_data = json.load(file)\n",
    "\n",
    "with open('Samples/sample_siirtokarjalaiset_annotated.json', 'r', encoding='utf-8') as file:\n",
    "    hand_data = json.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def parse_response(response_str):\n",
    "    lines = response_str.split('\\n')\n",
    "    parsed_response = {}\n",
    "    for line in lines:\n",
    "        key, _, value = line.partition(': ')\n",
    "        parsed_response[key] = value.strip() if value.strip() else None\n",
    "    return parsed_response\n",
    "\n",
    "\n",
    "# Checking how similar the words are\n",
    "def are_similar(str1, str2, threshold=70, context=None):\n",
    "    similarity = fuzz.token_set_ratio(str1, str2)\n",
    "    is_similar = similarity > threshold\n",
    "    \n",
    "    # Check if similarity is below 100% and store it if so\n",
    "    if is_similar and similarity < 100:\n",
    "        store_not_exact_matches(str1, str2, similarity, context)\n",
    "        \n",
    "    return is_similar\n",
    "\n",
    "\n",
    "def store_not_exact_matches(str1, str2, similarity, context):\n",
    "    data = {\n",
    "        \"string_1\": str1,\n",
    "        \"string_2\": str2,\n",
    "        \"similarity\": similarity,\n",
    "        \"context\": context  # This will provide additional information\n",
    "    }\n",
    "    with open(\"non_exact_matches.json\", \"a\", encoding=\"utf-8\") as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "        file.write(\",\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Matches: 350\n",
      "Total Mismatches: 486\n",
      "Match Percentage: 41.87%\n"
     ]
    }
   ],
   "source": [
    "def compare_values(api_values, annotated_values, context):\n",
    "    api_list = api_values.lower().split(', ') if api_values else []\n",
    "    annotated_list = annotated_values.lower().split(', ') if annotated_values else []\n",
    "    \n",
    "    matches = set()\n",
    "    mismatches = set(api_list).union(set(annotated_list))  \n",
    "    \n",
    "    for api_val in api_list:\n",
    "        for ann_val in annotated_list:\n",
    "            if are_similar(api_val, ann_val, context=context):\n",
    "                matches.add(api_val)\n",
    "                mismatches.discard(api_val)\n",
    "                mismatches.discard(ann_val)\n",
    "    \n",
    "    return matches, mismatches\n",
    "\n",
    "\n",
    "# Parse JSON strings\n",
    "api_responses = api_data\n",
    "hand_annotated = hand_data\n",
    "# Loop over all elements in api_responses and hand_annotated to compare them\n",
    "results = []\n",
    "total_matches = 0\n",
    "total_mismatches = 0\n",
    "\n",
    "for api_resp, hand_ann in zip(api_responses, hand_annotated):\n",
    "    parsed_api_response = parse_response(api_resp['api_response'])\n",
    "    \n",
    "    comparison_results = {\n",
    "        \"index\": hand_ann['index'],\n",
    "        \"person_name\": hand_ann['primary_person_name'],\n",
    "        \"spouse_name\": hand_ann['spouse_name'],\n",
    "        \"detail\": []\n",
    "    }\n",
    "    \n",
    "    for key in [\"person_hobbies\", \"person_social_orgs\", \"spouse_hobbies\", \"spouse_social_orgs\"]:\n",
    "        split_keys = key.split(\"_\")\n",
    "        api_key = split_keys[0].capitalize() + \"\".join(word.capitalize() for word in split_keys[1:])\n",
    "        \n",
    "        # Safely get the index values for context\n",
    "        api_person_index = api_resp.get('person_index', None)\n",
    "        annotated_person_index = hand_ann.get('index', None)\n",
    "        \n",
    "\n",
    "        # Build the context\n",
    "        context = {\n",
    "            \"api_person_index\": api_person_index +1,\n",
    "            \"annotated_person_index\": annotated_person_index,\n",
    "            \"category_type\": key\n",
    "        }\n",
    "        \n",
    "        matches, mismatches = compare_values(parsed_api_response.get(api_key, \"\"), hand_ann[key], context)\n",
    "        \n",
    "        detail = {\n",
    "            \"type\": key,\n",
    "            \"matches\": list(matches),\n",
    "            \"mismatches\": list(mismatches)\n",
    "        }\n",
    "        comparison_results[\"detail\"].append(detail)\n",
    "        \n",
    "        total_matches += len(matches)\n",
    "        total_mismatches += len(mismatches)\n",
    "    \n",
    "    results.append(comparison_results)\n",
    "\n",
    "output_json = json.dumps(results, indent=4, ensure_ascii=False)\n",
    "\n",
    "# To store the results in a file:\n",
    "with open(\"matches_results.json\", \"w\") as file:\n",
    "    file.write(output_json)\n",
    "\n",
    "# Printing total matches and mismatches\n",
    "print(f\"Total Matches: {total_matches}\")\n",
    "print(f\"Total Mismatches: {total_mismatches}\")\n",
    "\n",
    "# Calculating and printing the match percentage\n",
    "total_comparisons = total_matches + total_mismatches\n",
    "if total_comparisons > 0: \n",
    "    match_percentage = (total_matches / total_comparisons) * 100\n",
    "    print(f\"Match Percentage: {match_percentage:.2f}%\")\n",
    "else:\n",
    "    print(\"No comparisons were made (Total Comparisons: 0).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Person ---\n",
      "Total True Positives: 128\n",
      "Total False Positives: 161\n",
      "Total False Negatives: 194\n",
      "Precision: 0.44\n",
      "Recall: 0.40\n",
      "\n",
      "--- Spouse ---\n",
      "Total True Positives: 59\n",
      "Total False Positives: 193\n",
      "Total False Negatives: 213\n",
      "Precision: 0.23\n",
      "Recall: 0.22\n",
      "\n",
      "--- Overall ---\n",
      "Total True Positives: 187\n",
      "Total False Positives: 354\n",
      "Total False Negatives: 407\n",
      "Precision: 0.346\n",
      "Recall: 0.315\n",
      "F-score: 0.330\n"
     ]
    }
   ],
   "source": [
    "### Precision, recall and F Score \n",
    "\n",
    "def compare_values(api_dict, hand_ann_dict):\n",
    "    api_name = api_dict[\"api_response\"].split(\"PersonName:\")[1].split(\"\\n\")[0].strip()\n",
    "    api_hobbies = api_dict[\"api_response\"].split(\"PersonHobbies:\")[1].split(\"\\n\")[0].strip().split(', ')\n",
    "    api_social_orgs = api_dict[\"api_response\"].split(\"PersonSocialOrgs:\")[1].split(\"\\n\")[0].strip().split(', ')\n",
    "    api_spouse_hobbies = api_dict[\"api_response\"].split(\"SpouseHobbies:\")[1].split(\"\\n\")[0].strip().split(', ')\n",
    "    api_spouse_social_orgs = api_dict[\"api_response\"].split(\"SpouseSocialOrgs:\")[1].split(\"\\n\")[0].strip().split(', ')\n",
    "\n",
    "    hand_name = hand_ann_dict[\"primary_person_name\"]\n",
    "    hand_hobbies = hand_ann_dict[\"person_hobbies\"].split(', ')\n",
    "    hand_social_orgs = hand_ann_dict[\"person_social_orgs\"].split(', ')\n",
    "    hand_spouse_hobbies = hand_ann_dict[\"spouse_hobbies\"].split(', ')\n",
    "    hand_spouse_social_orgs = hand_ann_dict[\"spouse_social_orgs\"].split(', ')\n",
    "\n",
    "    # Assuming are_similar function is predefined\n",
    "\n",
    "    def calculate_metrics(api_values, hand_values):\n",
    "        TP = set()\n",
    "        FP = set(api_values)  # Temporarily assume all api_values are FP\n",
    "        FN = set(hand_values)  # Temporarily assume all annotated_values are FN\n",
    "        \n",
    "        for api_val in api_values:\n",
    "            for ann_val in hand_values:\n",
    "                if are_similar(api_val, ann_val):\n",
    "                    TP.add(api_val)  # Add to True Positives\n",
    "                    FP.discard(api_val)  # Remove from False Positives\n",
    "                    FN.discard(ann_val)  # Remove from False Negatives\n",
    "                    \n",
    "        precision = len(TP) / (len(TP) + len(FP)) if TP or FP else 0\n",
    "        recall = len(TP) / (len(TP) + len(FN)) if TP or FN else 0\n",
    "        f_score = (2 * precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "    \n",
    "        return TP, FP, FN, precision, recall, f_score\n",
    "\n",
    "    # Compute metrics for person and spouse separately\n",
    "    person_metrics = calculate_metrics(api_social_orgs, hand_social_orgs)\n",
    "    person_hobbies = calculate_metrics(api_hobbies, hand_hobbies)\n",
    "    spouse_metrics = calculate_metrics(api_spouse_social_orgs, hand_spouse_social_orgs)\n",
    "    spouse_hobbies = calculate_metrics(api_spouse_hobbies, hand_spouse_hobbies)\n",
    "\n",
    "    \n",
    "\n",
    "    return person_metrics, spouse_metrics, person_hobbies, spouse_hobbies\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "api_responses = api_data  # This should be your API data\n",
    "hand_annotated = hand_data  # This should be your hand annotated data\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "# Assume api_responses and hand_annotated are lists of strings for this example. \n",
    "# Modify as per your actual data structure.\n",
    "total_person_TP = total_person_FP = total_person_FN = 0\n",
    "total_spouse_TP = total_spouse_FP = total_spouse_FN = 0\n",
    "total_person_hobbies_TP = total_person_hobbies_FP = total_person_hobbies_FN = 0\n",
    "total_spouse_hobbies_TP = total_spouse_hobbies_FP = total_spouse_hobbies_FN = 0\n",
    "\n",
    "\n",
    "for index, (api_resp, hand_ann) in enumerate(zip(api_responses, hand_annotated)):\n",
    "    # Call compare_values and unpack all four return values here:\n",
    "    person_metrics, spouse_metrics, person_hobbies_metrics, spouse_hobbies_metrics = compare_values(api_resp, hand_ann)\n",
    "\n",
    "    total_person_TP += len(person_metrics[0])\n",
    "    total_person_FP += len(person_metrics[1])\n",
    "    total_person_FN += len(person_metrics[2])\n",
    "\n",
    "    total_spouse_TP += len(spouse_metrics[0])\n",
    "    total_spouse_FP += len(spouse_metrics[1])\n",
    "    total_spouse_FN += len(spouse_metrics[2])\n",
    "    \n",
    "    # Add handling for person_hobbies_metrics and spouse_hobbies_metrics\n",
    "    # For example:\n",
    "    total_person_hobbies_TP += len(person_hobbies_metrics[0])\n",
    "    total_person_hobbies_FP += len(person_hobbies_metrics[1])\n",
    "    total_person_hobbies_FN += len(person_hobbies_metrics[2])\n",
    "\n",
    "    total_spouse_hobbies_TP += len(spouse_hobbies_metrics[0])\n",
    "    total_spouse_hobbies_FP += len(spouse_hobbies_metrics[1])\n",
    "    total_spouse_hobbies_FN += len(spouse_hobbies_metrics[2])\n",
    "\n",
    "    results.append({\n",
    "    \"person_metrics\": {\n",
    "        \"index\": hand_ann['index'],\n",
    "        \"person_name\": hand_ann['primary_person_name'],\n",
    "        \"true_positives\": list(person_metrics[0]),\n",
    "        \"false_positives\": list(person_metrics[1]),\n",
    "        \"false_negatives\": list(person_metrics[2]),\n",
    "        \"precision\": person_metrics[3],\n",
    "        \"recall\": person_metrics[4],\n",
    "        \"f_score\": person_metrics[5]\n",
    "    },\n",
    "    \"person_hobbies_metrics\": {\n",
    "        \"true_positives\": list(person_hobbies_metrics[0]),\n",
    "        \"false_positives\": list(person_hobbies_metrics[1]),\n",
    "        \"false_negatives\": list(person_hobbies_metrics[2]),\n",
    "        \"precision\": person_hobbies_metrics[3],\n",
    "        \"recall\": person_hobbies_metrics[4],\n",
    "        \"f_score\": person_hobbies_metrics[5]\n",
    "    },\n",
    "    \"spouse_metrics\": {\n",
    "        \"true_positives\": list(spouse_metrics[0]),\n",
    "        \"false_positives\": list(spouse_metrics[1]),\n",
    "        \"false_negatives\": list(spouse_metrics[2]),\n",
    "        \"precision\": spouse_metrics[3],\n",
    "        \"recall\": spouse_metrics[4],\n",
    "        \"f_score\": spouse_metrics[5]\n",
    "    },\n",
    "    \"spouse_hobbies_metrics\": {\n",
    "        \"true_positives\": list(spouse_hobbies_metrics[0]),\n",
    "        \"false_positives\": list(spouse_hobbies_metrics[1]),\n",
    "        \"false_negatives\": list(spouse_hobbies_metrics[2]),\n",
    "        \"precision\": spouse_hobbies_metrics[3],\n",
    "        \"recall\": spouse_hobbies_metrics[4],\n",
    "        \"f_score\": spouse_hobbies_metrics[5]\n",
    "    }\n",
    "})\n",
    "\n",
    "\n",
    "# Constructing a summary of results for final output\n",
    "person_precision = total_person_TP / (total_person_TP + total_person_FP) if total_person_TP + total_person_FP > 0 else 0\n",
    "person_recall = total_person_TP / (total_person_TP + total_person_FN) if total_person_TP + total_person_FN > 0 else 0\n",
    "spouse_precision = total_spouse_TP / (total_spouse_TP + total_spouse_FP) if total_spouse_TP + total_spouse_FP > 0 else 0\n",
    "spouse_recall = total_spouse_TP / (total_spouse_TP + total_spouse_FN) if total_spouse_TP + total_spouse_FN > 0 else 0\n",
    "\n",
    "# Calculate overall metrics\n",
    "overall_TP = total_person_TP + total_spouse_TP\n",
    "overall_FP = total_person_FP + total_spouse_FP\n",
    "overall_FN = total_person_FN + total_spouse_FN\n",
    "\n",
    "overall_precision = overall_TP / (overall_TP + overall_FP) if (overall_TP + overall_FP) > 0 else 0\n",
    "overall_recall = overall_TP / (overall_TP + overall_FN) if (overall_TP + overall_FN) > 0 else 0\n",
    "overall_f_score = (2 * overall_precision * overall_recall) / (overall_precision + overall_recall) if (overall_precision + overall_recall) > 0 else 0\n",
    "\n",
    "# Round to 3 decimal places\n",
    "overall_precision = round(overall_precision, 3)\n",
    "overall_recall = round(overall_recall, 3)\n",
    "overall_f_score = round(overall_f_score, 3)\n",
    "\n",
    "summary = {\n",
    "    \"person\": {\n",
    "        \"total_true_positives\": total_person_TP,\n",
    "        \"total_false_positives\": total_person_FP,\n",
    "        \"total_false_negatives\": total_person_FN,\n",
    "        \"precision\": person_precision,\n",
    "        \"recall\": person_recall,\n",
    "        \"f_score\": (2 * person_precision * person_recall) / (person_precision + person_recall) if person_precision + person_recall > 0 else 0\n",
    "    },\n",
    "    \"spouse\": {\n",
    "        \"total_true_positives\": total_spouse_TP,\n",
    "        \"total_false_positives\": total_spouse_FP,\n",
    "        \"total_false_negatives\": total_spouse_FN,\n",
    "        \"precision\": spouse_precision,\n",
    "        \"recall\": spouse_recall,\n",
    "        \"f_score\": (2 * spouse_precision * spouse_recall) / (spouse_precision + spouse_recall) if spouse_precision + spouse_recall > 0 else 0\n",
    "    }, \n",
    "    \"overall\": {\n",
    "        \"total_true_positives\": overall_TP,\n",
    "        \"total_false_positives\": overall_FP,\n",
    "        \"total_false_negatives\": overall_FN,\n",
    "        \"precision\": overall_precision,\n",
    "        \"recall\": overall_recall,\n",
    "        \"f_score\": overall_f_score\n",
    "    }\n",
    "}\n",
    "for key in summary:\n",
    "    summary[key]['precision'] = round(summary[key]['precision'], 3)\n",
    "    summary[key]['recall'] = round(summary[key]['recall'], 3)\n",
    "    summary[key]['f_score'] = round(summary[key]['f_score'], 3)\n",
    "\n",
    "\n",
    "# Final JSON output to include both the detailed results and the summary\n",
    "output_data = {\n",
    "    \"summary\": summary,\n",
    "    \"results\": results\n",
    "}\n",
    "\n",
    "# Storing in JSON format\n",
    "output_json = json.dumps(output_data, indent=4, ensure_ascii=False)\n",
    "\n",
    "# To store the results in a file:\n",
    "with open(\"precision_recall_results.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(output_json)\n",
    "\n",
    "# Printing total matches and mismatches\n",
    "print(f\"--- Person ---\")\n",
    "print(f\"Total True Positives: {total_person_TP}\")\n",
    "print(f\"Total False Positives: {total_person_FP}\")\n",
    "print(f\"Total False Negatives: {total_person_FN}\")\n",
    "print(f\"Precision: {summary['person']['precision']:.2f}\")\n",
    "print(f\"Recall: {summary['person']['recall']:.2f}\")\n",
    "print(f\"\\n--- Spouse ---\")\n",
    "print(f\"Total True Positives: {total_spouse_TP}\")\n",
    "print(f\"Total False Positives: {total_spouse_FP}\")\n",
    "print(f\"Total False Negatives: {total_spouse_FN}\")\n",
    "print(f\"Precision: {summary['spouse']['precision']:.2f}\")\n",
    "print(f\"Recall: {summary['spouse']['recall']:.2f}\")\n",
    "print(f\"\\n--- Overall ---\")\n",
    "print(f\"Total True Positives: {overall_TP}\")\n",
    "print(f\"Total False Positives: {overall_FP}\")\n",
    "print(f\"Total False Negatives: {overall_FN}\")\n",
    "print(f\"Precision: {overall_precision:.3f}\")\n",
    "print(f\"Recall: {overall_recall:.3f}\")\n",
    "print(f\"F-score: {overall_f_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation for true negative\n",
    "## Basicly adding emptylabel in true positive if there is no false positive or false negative\n",
    "\n",
    "# Load the JSON data\n",
    "with open('precision_recall_results.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Iterate through the \"results\" section\n",
    "for result in data['results']:\n",
    "    for metric_key, metric_value in result.items():\n",
    "        \n",
    "        # Check if all entities are empty\n",
    "        if not any(metric_value['true_positives']) and \\\n",
    "           not any(metric_value['false_positives']) and \\\n",
    "           not any(metric_value['false_negatives']):\n",
    "            metric_value['true_positives'] = [\"emptylabel\"]\n",
    "            metric_value['f_score'] = 1.0\n",
    "            metric_value['precision'] = 1.0\n",
    "            metric_value['recall'] = 1.0\n",
    "        else:\n",
    "            # Calculate precision, recall, and F-score\n",
    "            try:\n",
    "                metric_value['precision'] = len(metric_value['true_positives']) / \\\n",
    "                                            (len(metric_value['true_positives']) + len(metric_value['false_positives']))\n",
    "            except ZeroDivisionError:\n",
    "                metric_value['precision'] = 0.0\n",
    "                \n",
    "            try:\n",
    "                metric_value['recall'] = len(metric_value['true_positives']) / \\\n",
    "                                         (len(metric_value['true_positives']) + len(metric_value['false_negatives']))\n",
    "            except ZeroDivisionError:\n",
    "                metric_value['recall'] = 0.0\n",
    "                \n",
    "            try:\n",
    "                metric_value['f_score'] = 2 * (metric_value['precision'] * metric_value['recall']) / \\\n",
    "                                          (metric_value['precision'] + metric_value['recall'])\n",
    "            except ZeroDivisionError:\n",
    "                metric_value['f_score'] = 0.0\n",
    "\n",
    "# Save the updated data back to the JSON file\n",
    "with open('precision_recall_updated_results.json', 'w') as file:\n",
    "    json.dump(data, file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculating for summary for all categories\n",
    "#micro f score\n",
    "\n",
    "\n",
    "def calculate_metrics(TP, FP, FN):\n",
    "    try:\n",
    "        precision = round((TP / (TP + FP)) if TP + FP != 0 else 0, 2)\n",
    "    except ZeroDivisionError:\n",
    "        precision = 0.0\n",
    "        \n",
    "    try:\n",
    "        recall = round((TP / (TP + FN)) if TP + FN != 0 else 0, 2)\n",
    "    except ZeroDivisionError:\n",
    "        recall = 0.0\n",
    "        \n",
    "    try:\n",
    "        f_score = round((2 * precision * recall) / (precision + recall) if precision + recall != 0 else 0, 2)\n",
    "    except ZeroDivisionError:\n",
    "        f_score = 0.0\n",
    "    \n",
    "    return precision, recall, f_score\n",
    "\n",
    "# Load the JSON data\n",
    "with open('precision_recall_updated_results.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize metrics counters\n",
    "metrics_counter = {\n",
    "    \"person\": {\"TP\": 0, \"FP\": 0, \"FN\": 0},\n",
    "    \"spouse\": {\"TP\": 0, \"FP\": 0, \"FN\": 0},\n",
    "    \"overall\": {\"TP\": 0, \"FP\": 0, \"FN\": 0},\n",
    "    \"social_orgs\": {\"TP\": 0, \"FP\": 0, \"FN\": 0},\n",
    "    \"hobbies\": {\"TP\": 0, \"FP\": 0, \"FN\": 0},\n",
    "    \"person_social_orgs\": {\"TP\": 0, \"FP\": 0, \"FN\": 0},\n",
    "    \"person_hobbies\": {\"TP\": 0, \"FP\": 0, \"FN\": 0},\n",
    "    \"spouse_social_orgs\": {\"TP\": 0, \"FP\": 0, \"FN\": 0},\n",
    "    \"spouse_hobbies\": {\"TP\": 0, \"FP\": 0, \"FN\": 0},\n",
    "}\n",
    "\n",
    "# Iterate through the \"results\" section\n",
    "for result in data['results']:\n",
    "    for key, value in result.items():\n",
    "        if \"person_metrics\" in key:\n",
    "            # adding persons social orgs to person_social_orgs\n",
    "            metrics_counter[\"person_social_orgs\"][\"TP\"] += len(value[\"true_positives\"])\n",
    "            metrics_counter[\"person_social_orgs\"][\"FP\"] += len(value[\"false_positives\"])\n",
    "            metrics_counter[\"person_social_orgs\"][\"FN\"] += len(value[\"false_negatives\"])\n",
    "            # adding social orgs into person\n",
    "            metrics_counter[\"person\"][\"TP\"] += len(value[\"true_positives\"])\n",
    "            metrics_counter[\"person\"][\"FP\"] += len(value[\"false_positives\"])\n",
    "            metrics_counter[\"person\"][\"FN\"] += len(value[\"false_negatives\"])\n",
    "            # adding person social orgs into social orgs\n",
    "            metrics_counter[\"social_orgs\"][\"TP\"] += len(value[\"true_positives\"])\n",
    "            metrics_counter[\"social_orgs\"][\"FP\"] += len(value[\"false_positives\"])\n",
    "            metrics_counter[\"social_orgs\"][\"FN\"] += len(value[\"false_negatives\"])\n",
    "\n",
    "        if \"person_hobbies_metrics\" in key:\n",
    "            #adding person hobbies into person hobbies\n",
    "            metrics_counter[\"person_hobbies\"][\"TP\"] += len(value[\"true_positives\"])\n",
    "            metrics_counter[\"person_hobbies\"][\"FP\"] += len(value[\"false_positives\"])\n",
    "            metrics_counter[\"person_hobbies\"][\"FN\"] += len(value[\"false_negatives\"])            \n",
    "            #adding person hobbies into person\n",
    "            metrics_counter[\"person\"][\"TP\"] += len(value[\"true_positives\"])\n",
    "            metrics_counter[\"person\"][\"FP\"] += len(value[\"false_positives\"])\n",
    "            metrics_counter[\"person\"][\"FN\"] += len(value[\"false_negatives\"])\n",
    "            #adding person hobbies into hobbies\n",
    "            metrics_counter[\"hobbies\"][\"TP\"] += len(value[\"true_positives\"])\n",
    "            metrics_counter[\"hobbies\"][\"FP\"] += len(value[\"false_positives\"])\n",
    "            metrics_counter[\"hobbies\"][\"FN\"] += len(value[\"false_negatives\"])\n",
    "\n",
    "\n",
    "        if \"spouse_metrics\" in key:\n",
    "            #adding spouse social orgs into spouse social orgs\n",
    "            metrics_counter[\"spouse_social_orgs\"][\"TP\"] += len(value[\"true_positives\"])\n",
    "            metrics_counter[\"spouse_social_orgs\"][\"FP\"] += len(value[\"false_positives\"])\n",
    "            metrics_counter[\"spouse_social_orgs\"][\"FN\"] += len(value[\"false_negatives\"])           \n",
    "            #adding spouse social orgs into spouse\n",
    "            metrics_counter[\"spouse\"][\"TP\"] += len(value[\"true_positives\"])\n",
    "            metrics_counter[\"spouse\"][\"FP\"] += len(value[\"false_positives\"])\n",
    "            metrics_counter[\"spouse\"][\"FN\"] += len(value[\"false_negatives\"])\n",
    "            #adding spouse social orgs into social orgs\n",
    "            metrics_counter[\"social_orgs\"][\"TP\"] += len(value[\"true_positives\"])\n",
    "            metrics_counter[\"social_orgs\"][\"FP\"] += len(value[\"false_positives\"])\n",
    "            metrics_counter[\"social_orgs\"][\"FN\"] += len(value[\"false_negatives\"])\n",
    "\n",
    "        if \"spouse_hobbies_metrics\" in key:\n",
    "            #adding spouse hobbies into spouse hobbies\n",
    "            metrics_counter[\"spouse_hobbies\"][\"TP\"] += len(value[\"true_positives\"])\n",
    "            metrics_counter[\"spouse_hobbies\"][\"FP\"] += len(value[\"false_positives\"])\n",
    "            metrics_counter[\"spouse_hobbies\"][\"FN\"] += len(value[\"false_negatives\"])\n",
    "            #adding spouse hobbies into spouse\n",
    "            metrics_counter[\"spouse\"][\"TP\"] += len(value[\"true_positives\"])\n",
    "            metrics_counter[\"spouse\"][\"FP\"] += len(value[\"false_positives\"])\n",
    "            metrics_counter[\"spouse\"][\"FN\"] += len(value[\"false_negatives\"])\n",
    "            #adding spouse hobbies into hobbies\n",
    "            metrics_counter[\"hobbies\"][\"TP\"] += len(value[\"true_positives\"])\n",
    "            metrics_counter[\"hobbies\"][\"FP\"] += len(value[\"false_positives\"])\n",
    "            metrics_counter[\"hobbies\"][\"FN\"] += len(value[\"false_negatives\"])\n",
    "\n",
    "\n",
    "        # Update overall metrics\n",
    "        metrics_counter[\"overall\"][\"TP\"] += len(value[\"true_positives\"])\n",
    "        metrics_counter[\"overall\"][\"FP\"] += len(value[\"false_positives\"])\n",
    "        metrics_counter[\"overall\"][\"FN\"] += len(value[\"false_negatives\"])\n",
    "\n",
    "# Update summary metrics in data\n",
    "for category, metrics in metrics_counter.items():\n",
    "    precision, recall, f_score = calculate_metrics(metrics[\"TP\"], metrics[\"FP\"], metrics[\"FN\"])\n",
    "    data[\"summary\"][category] = {\n",
    "        \"total_true_positives\": metrics[\"TP\"],\n",
    "        \"total_false_positives\": metrics[\"FP\"],\n",
    "        \"total_false_negatives\": metrics[\"FN\"],\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f_score\": f_score\n",
    "    }\n",
    "\n",
    "# Save the updated data back to the JSON file\n",
    "with open('precision_recall_updated_results.json', 'w') as file:\n",
    "    json.dump(data, file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-average Precision: 0.71\n",
      "Macro-average Recall: 0.71\n",
      "Macro-average F-score: 0.71\n",
      "--\n",
      "Micro-average Precision: 0.52\n",
      "Micro-average Recall: 0.48\n",
      "Micro-average F-score: 0.50\n",
      "----------\n",
      "Person 1 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 2 - Average Precision: 1.00, Average Recall: 0.92, Average F-score: 0.95\n",
      "Person 3 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 4 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 5 - Average Precision: 0.00, Average Recall: 0.00, Average F-score: 0.00\n",
      "Person 6 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 7 - Average Precision: 0.40, Average Recall: 0.50, Average F-score: 0.44\n",
      "Person 8 - Average Precision: 0.25, Average Recall: 0.25, Average F-score: 0.25\n",
      "Person 9 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 10 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 11 - Average Precision: 0.25, Average Recall: 0.25, Average F-score: 0.25\n",
      "Person 12 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 13 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 14 - Average Precision: 0.50, Average Recall: 0.50, Average F-score: 0.50\n",
      "Person 15 - Average Precision: 0.00, Average Recall: 0.00, Average F-score: 0.00\n",
      "Person 16 - Average Precision: 0.50, Average Recall: 0.50, Average F-score: 0.50\n",
      "Person 17 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 18 - Average Precision: 1.00, Average Recall: 0.81, Average F-score: 0.88\n",
      "Person 19 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 20 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 21 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 22 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 23 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 24 - Average Precision: 0.95, Average Recall: 0.95, Average F-score: 0.95\n",
      "Person 25 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 26 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 27 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 28 - Average Precision: 0.88, Average Recall: 0.88, Average F-score: 0.88\n",
      "Person 29 - Average Precision: 0.69, Average Recall: 0.75, Average F-score: 0.71\n",
      "Person 30 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 31 - Average Precision: 0.25, Average Recall: 0.25, Average F-score: 0.25\n",
      "Person 32 - Average Precision: 0.50, Average Recall: 0.50, Average F-score: 0.50\n",
      "Person 33 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 34 - Average Precision: 0.50, Average Recall: 0.50, Average F-score: 0.50\n",
      "Person 35 - Average Precision: 0.25, Average Recall: 0.25, Average F-score: 0.25\n",
      "Person 36 - Average Precision: 0.25, Average Recall: 0.25, Average F-score: 0.25\n",
      "Person 37 - Average Precision: 0.75, Average Recall: 0.62, Average F-score: 0.67\n",
      "Person 38 - Average Precision: 0.25, Average Recall: 0.25, Average F-score: 0.25\n",
      "Person 39 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 40 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 41 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 42 - Average Precision: 0.25, Average Recall: 0.25, Average F-score: 0.25\n",
      "Person 43 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 44 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 45 - Average Precision: 0.75, Average Recall: 0.67, Average F-score: 0.70\n",
      "Person 46 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 47 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 48 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 49 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 50 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 51 - Average Precision: 0.50, Average Recall: 0.50, Average F-score: 0.50\n",
      "Person 52 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 53 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 54 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 55 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 56 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 57 - Average Precision: 0.88, Average Recall: 0.88, Average F-score: 0.88\n",
      "Person 58 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 59 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 60 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 61 - Average Precision: 1.00, Average Recall: 0.59, Average F-score: 0.65\n",
      "Person 62 - Average Precision: 0.50, Average Recall: 0.50, Average F-score: 0.50\n",
      "Person 63 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 64 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 65 - Average Precision: 0.50, Average Recall: 0.50, Average F-score: 0.50\n",
      "Person 66 - Average Precision: 0.25, Average Recall: 0.25, Average F-score: 0.25\n",
      "Person 67 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 68 - Average Precision: 0.92, Average Recall: 0.92, Average F-score: 0.92\n",
      "Person 69 - Average Precision: 0.85, Average Recall: 0.92, Average F-score: 0.88\n",
      "Person 70 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 71 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 72 - Average Precision: 0.71, Average Recall: 0.75, Average F-score: 0.73\n",
      "Person 73 - Average Precision: 0.25, Average Recall: 0.25, Average F-score: 0.25\n",
      "Person 74 - Average Precision: 0.00, Average Recall: 0.00, Average F-score: 0.00\n",
      "Person 75 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 76 - Average Precision: 0.50, Average Recall: 0.50, Average F-score: 0.50\n",
      "Person 77 - Average Precision: 0.25, Average Recall: 0.25, Average F-score: 0.25\n",
      "Person 78 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 79 - Average Precision: 0.00, Average Recall: 0.00, Average F-score: 0.00\n",
      "Person 80 - Average Precision: 0.00, Average Recall: 0.00, Average F-score: 0.00\n",
      "Person 81 - Average Precision: 0.00, Average Recall: 0.00, Average F-score: 0.00\n",
      "Person 82 - Average Precision: 0.75, Average Recall: 0.70, Average F-score: 0.72\n",
      "Person 83 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 84 - Average Precision: 0.50, Average Recall: 0.50, Average F-score: 0.50\n",
      "Person 85 - Average Precision: 0.88, Average Recall: 1.00, Average F-score: 0.92\n",
      "Person 86 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 87 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 88 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 89 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 90 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 91 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 92 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 93 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 94 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 95 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 96 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 97 - Average Precision: 0.25, Average Recall: 0.25, Average F-score: 0.25\n",
      "Person 98 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 99 - Average Precision: 0.50, Average Recall: 0.50, Average F-score: 0.50\n",
      "Person 100 - Average Precision: 0.25, Average Recall: 0.25, Average F-score: 0.25\n",
      "Person 101 - Average Precision: 0.00, Average Recall: 0.00, Average F-score: 0.00\n",
      "Person 102 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 103 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 104 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 105 - Average Precision: 0.25, Average Recall: 0.25, Average F-score: 0.25\n",
      "Person 106 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 107 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 108 - Average Precision: 0.50, Average Recall: 0.50, Average F-score: 0.50\n",
      "Person 109 - Average Precision: 0.25, Average Recall: 0.25, Average F-score: 0.25\n",
      "Person 110 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 111 - Average Precision: 0.25, Average Recall: 0.25, Average F-score: 0.25\n",
      "Person 112 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 113 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 114 - Average Precision: 0.50, Average Recall: 0.50, Average F-score: 0.50\n",
      "Person 115 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 116 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 117 - Average Precision: 0.25, Average Recall: 0.25, Average F-score: 0.25\n",
      "Person 118 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 119 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 120 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 121 - Average Precision: 0.75, Average Recall: 0.65, Average F-score: 0.69\n",
      "Person 122 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 123 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 124 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 125 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 126 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 127 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 128 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 129 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 130 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 131 - Average Precision: 0.25, Average Recall: 0.25, Average F-score: 0.25\n",
      "Person 132 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 133 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 134 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 135 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 136 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 137 - Average Precision: 0.38, Average Recall: 0.50, Average F-score: 0.42\n",
      "Person 138 - Average Precision: 1.00, Average Recall: 0.94, Average F-score: 0.96\n",
      "Person 139 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 140 - Average Precision: 0.25, Average Recall: 0.25, Average F-score: 0.25\n",
      "Person 141 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 142 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 143 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 144 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 145 - Average Precision: 0.25, Average Recall: 0.25, Average F-score: 0.25\n",
      "Person 146 - Average Precision: 0.25, Average Recall: 0.25, Average F-score: 0.25\n",
      "Person 147 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 148 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 149 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 150 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 151 - Average Precision: 0.00, Average Recall: 0.00, Average F-score: 0.00\n",
      "Person 152 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 153 - Average Precision: 0.50, Average Recall: 0.50, Average F-score: 0.50\n",
      "Person 154 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 155 - Average Precision: 0.73, Average Recall: 0.73, Average F-score: 0.73\n",
      "Person 156 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 157 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 158 - Average Precision: 0.50, Average Recall: 0.50, Average F-score: 0.50\n",
      "Person 159 - Average Precision: 0.33, Average Recall: 0.33, Average F-score: 0.25\n",
      "Person 160 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 161 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 162 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 163 - Average Precision: 0.50, Average Recall: 0.50, Average F-score: 0.50\n",
      "Person 164 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 165 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 166 - Average Precision: 0.50, Average Recall: 0.50, Average F-score: 0.50\n",
      "Person 167 - Average Precision: 0.50, Average Recall: 0.50, Average F-score: 0.50\n",
      "Person 168 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 169 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 170 - Average Precision: 0.50, Average Recall: 0.50, Average F-score: 0.50\n",
      "Person 171 - Average Precision: 0.25, Average Recall: 0.25, Average F-score: 0.25\n",
      "Person 172 - Average Precision: 0.67, Average Recall: 0.67, Average F-score: 0.67\n",
      "Person 173 - Average Precision: 0.88, Average Recall: 1.00, Average F-score: 0.92\n",
      "Person 174 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 175 - Average Precision: 0.50, Average Recall: 0.50, Average F-score: 0.50\n",
      "Person 176 - Average Precision: 0.25, Average Recall: 0.25, Average F-score: 0.25\n",
      "Person 177 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 178 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 179 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 180 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 181 - Average Precision: 0.50, Average Recall: 0.50, Average F-score: 0.50\n",
      "Person 182 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 183 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 184 - Average Precision: 0.08, Average Recall: 0.12, Average F-score: 0.10\n",
      "Person 185 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n",
      "Person 186 - Average Precision: 0.50, Average Recall: 0.50, Average F-score: 0.50\n",
      "Person 187 - Average Precision: 0.12, Average Recall: 0.25, Average F-score: 0.17\n",
      "Person 188 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 189 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 190 - Average Precision: 0.50, Average Recall: 0.50, Average F-score: 0.50\n",
      "Person 191 - Average Precision: 0.25, Average Recall: 0.12, Average F-score: 0.17\n",
      "Person 192 - Average Precision: 0.62, Average Recall: 0.69, Average F-score: 0.63\n",
      "Person 193 - Average Precision: 1.00, Average Recall: 0.83, Average F-score: 0.88\n",
      "Person 194 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 195 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 196 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 197 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 198 - Average Precision: 0.25, Average Recall: 0.25, Average F-score: 0.25\n",
      "Person 199 - Average Precision: 1.00, Average Recall: 1.00, Average F-score: 1.00\n",
      "Person 200 - Average Precision: 0.75, Average Recall: 0.75, Average F-score: 0.75\n"
     ]
    }
   ],
   "source": [
    "## calculating for summary for all categories\n",
    "#macro f score\n",
    "\n",
    "# Load the JSON data\n",
    "with open('precision_recall_updated_results.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "averages = []\n",
    "\n",
    "for result in data[\"results\"]:\n",
    "    precision_sum = 0.0\n",
    "    recall_sum = 0.0\n",
    "    f_score_sum = 0.0\n",
    "    \n",
    "    entities = [\"person_metrics\", \"person_hobbies_metrics\", \"spouse_metrics\", \"spouse_hobbies_metrics\"]\n",
    "    num_entities = len(entities)\n",
    "    \n",
    "    for entity in entities:\n",
    "        precision_sum += result[entity][\"precision\"]\n",
    "        recall_sum += result[entity][\"recall\"]\n",
    "        f_score_sum += result[entity][\"f_score\"]\n",
    "    \n",
    "    avg_precision = precision_sum / num_entities\n",
    "    avg_recall = recall_sum / num_entities\n",
    "    avg_f_score = f_score_sum / num_entities\n",
    "    \n",
    "    averages.append({\n",
    "        \"average_precision\": avg_precision,\n",
    "        \"average_recall\": avg_recall,\n",
    "        \"average_f_score\": avg_f_score\n",
    "    })\n",
    "\n",
    "# Now `averages` contains the average precision, recall, and F-score\n",
    "# for each person in the original \"results\" array.\n",
    "\n",
    "total_precision = 0.0\n",
    "total_recall = 0.0\n",
    "total_f_score = 0.0\n",
    "num_instances = len(averages)\n",
    "\n",
    "# Summing up all the average scores\n",
    "for avg in averages:\n",
    "    total_precision += avg['average_precision']\n",
    "    total_recall += avg['average_recall']\n",
    "    total_f_score += avg['average_f_score']\n",
    "\n",
    "# Calculating the macro-average for all instances\n",
    "macro_avg_precision = total_precision / num_instances\n",
    "macro_avg_recall = total_recall / num_instances\n",
    "macro_avg_f_score = total_f_score / num_instances\n",
    "\n",
    "micro_avg_precision = round((metrics_counter[\"overall\"][\"TP\"] / (metrics_counter[\"overall\"][\"TP\"] + metrics_counter[\"overall\"][\"FP\"])) if metrics_counter[\"overall\"][\"TP\"] + metrics_counter[\"overall\"][\"FP\"] != 0 else 0, 2)\n",
    "micro_avg_recall = round((metrics_counter[\"overall\"][\"TP\"] / (metrics_counter[\"overall\"][\"TP\"] + metrics_counter[\"overall\"][\"FN\"])) if metrics_counter[\"overall\"][\"TP\"] + metrics_counter[\"overall\"][\"FN\"] != 0 else 0, 2)\n",
    "micro_avg_f_score = round((2 * micro_avg_precision * micro_avg_recall) / (micro_avg_precision + micro_avg_recall) if micro_avg_precision + micro_avg_recall != 0 else 0, 2)\n",
    "\n",
    "data[\"summary\"][\"micro_average\"] = {\n",
    "    \"total_true_positives\": metrics_counter[\"overall\"][\"TP\"],\n",
    "    \"total_false_positives\": metrics_counter[\"overall\"][\"FP\"],\n",
    "    \"total_false_negatives\": metrics_counter[\"overall\"][\"FN\"],\n",
    "    \"precision\": micro_avg_precision,\n",
    "    \"recall\": micro_avg_recall,\n",
    "    \"f_score\": micro_avg_f_score\n",
    "}\n",
    "\n",
    "# Add macro averages to the summary\n",
    "data[\"summary\"][\"macro_average\"] = {\n",
    "    \"total_true_positives\": None,  # These values are not defined in macro-averaging\n",
    "    \"total_false_positives\": None,  # These values are not defined in macro-averaging\n",
    "    \"total_false_negatives\": None,  # These values are not defined in macro-averaging\n",
    "    \"precision\": macro_avg_precision,\n",
    "    \"recall\": macro_avg_recall,\n",
    "    \"f_score\": macro_avg_f_score\n",
    "}\n",
    "\n",
    "# Save the updated data back to the JSON file\n",
    "with open('precision_recall_updated_results.json', 'w') as file:\n",
    "    json.dump(data, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "# Print Macro and Micro averages\n",
    "print(f\"Macro-average Precision: {macro_avg_precision:.2f}\")\n",
    "print(f\"Macro-average Recall: {macro_avg_recall:.2f}\")\n",
    "print(f\"Macro-average F-score: {macro_avg_f_score:.2f}\")\n",
    "print(\"--\")\n",
    "print(f\"Micro-average Precision: {data['summary']['micro_average']['precision']:.2f}\")\n",
    "print(f\"Micro-average Recall: {data['summary']['micro_average']['recall']:.2f}\")\n",
    "print(f\"Micro-average F-score: {data['summary']['micro_average']['f_score']:.2f}\")\n",
    "print(\"----------\")\n",
    "for i, avg in enumerate(averages):\n",
    "   print(f\"Person {i+1} - Average Precision: {avg['average_precision']:.2f}, Average Recall: {avg['average_recall']:.2f}, Average F-score: {avg['average_f_score']:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
