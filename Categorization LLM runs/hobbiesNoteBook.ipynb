{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1979adb-83c1-4c68-83f0-9c3e5666e20e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import math\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import datetime\n",
    "# Ensure raw output directory exists\n",
    "raw_output_dir = 'data/raw_output'\n",
    "os.makedirs(raw_output_dir, exist_ok=True)\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Your OpenAI API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Read the JSON file\n",
    "with open('data/datadump/hobbiesforapi.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "hobbies = list(data['HobbiesCount'].keys())\n",
    "\n",
    "# Combine all categories into one list, including non-hobby categories\n",
    "all_categories = [\n",
    "    \"käsityöt\", \"yksilöurheilu\", \"kirjallisuus\", \"ryhmäurheilu\", \"musiikki\", \"valokuvaus\",\n",
    "    \"kalastus\", \"metsästys\", \"vapaaehtoistoiminta\", \"pelit\", \"ei mainintaa\", \"työ/ammatti\", \"organisaatiot\"\n",
    "]\n",
    "\n",
    "# Global data structures\n",
    "categories = {category: [] for category in all_categories}\n",
    "unmatched_hobbies = []\n",
    "\n",
    "def load_data():\n",
    "    global categories, unmatched_hobbies\n",
    "    try:\n",
    "        with open('data/categorized_hobbies.json', 'r', encoding='utf-8') as f:\n",
    "            categories = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"No existing category data found. Initializing with empty categories.\")\n",
    "\n",
    "    try:\n",
    "        with open('data/unmatched_hobbies.json', 'r', encoding='utf-8') as f:\n",
    "            unmatched_hobbies = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        unmatched_hobbies = []\n",
    "        print(\"No unmatched hobbies data found. Starting with an empty list.\")\n",
    "\n",
    "def save_data():\n",
    "    with open('data/categorized_hobbies.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(categories, f, ensure_ascii=False, indent=4)\n",
    "    with open('data/unmatched_hobbies.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(unmatched_hobbies, f, ensure_ascii=False, indent=4)\n",
    "    print(\"Data saved to files.\")\n",
    "\n",
    "def save_hobby(hobby, category):\n",
    "    global all_categories  # Ensure we are modifying the global variable\n",
    "    # List of phrases that might indicate a new category\n",
    "    new_category_indicators = [\"new category, \", \"uusi kategoria, \", \"uusi kategori, \"]\n",
    "\n",
    "    # Check if the category input starts with any of the specified new category indicators\n",
    "    new_category = None\n",
    "    for indicator in new_category_indicators:\n",
    "        if category.startswith(indicator):\n",
    "            new_category = category.split(indicator)[1].strip()\n",
    "            break\n",
    "\n",
    "    if new_category:\n",
    "        if new_category not in categories:\n",
    "            categories[new_category] = []\n",
    "            all_categories.append(new_category)  # Add to all_categories here\n",
    "        categories[new_category].append(hobby)\n",
    "    elif category in categories:\n",
    "        categories[category].append(hobby)\n",
    "    else:\n",
    "        unmatched_hobbies.append(hobby)\n",
    "    save_data()\n",
    "\n",
    "\n",
    "def destroy_categories(category_names):\n",
    "    global all_categories  # Ensure we are modifying the global variable\n",
    "    # Load the current state of data\n",
    "    load_data()\n",
    "    \n",
    "    for category_name in category_names:\n",
    "        if category_name in categories:\n",
    "            destroyed_hobbies = categories.pop(category_name)\n",
    "            unmatched_hobbies.extend(destroyed_hobbies)\n",
    "            all_categories = [cat for cat in all_categories if cat != category_name]  # Rebuild all_categories\n",
    "            print(f\"Category '{category_name}' has been destroyed. Its hobbies have been moved to unmatched hobbies.\")\n",
    "        else:\n",
    "            print(f\"Category '{category_name}' not found.\")\n",
    "    \n",
    "    save_data()  # Save data only once after all categories have been processed\n",
    "\n",
    "\n",
    "\n",
    "def recategorize_unmatched_hobbies():\n",
    "    load_data()\n",
    "    batch_size = 50\n",
    "    num_batches = math.ceil(len(unmatched_hobbies) / batch_size)\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = min((i + 1) * batch_size, len(unmatched_hobbies))\n",
    "        hobbies_batch = unmatched_hobbies[batch_start:batch_end]\n",
    "        \n",
    "        print(f\"Recategorizing batch {i + 1}/{num_batches}\")\n",
    "        response, original_hobbies = categorize_hobby_batch(hobbies_batch, from_unmatched=True)\n",
    "        process_categorized_data(response, original_hobbies)\n",
    "        \n",
    "        print(f\"Batch {i + 1} processed\")\n",
    "\n",
    "    save_data()  # Save data after all batches have been processed\n",
    "\n",
    "\n",
    "def categorize_hobby_batch(hobbies_batch, from_unmatched=False):\n",
    "    global all_categories \n",
    "    \"\"\"Generate a prompt for categorizing a batch of hobbies, with special instructions for unmatched hobbies.\"\"\"\n",
    "\n",
    "    introduction = \"You are a helpful assistant tasked with categorizing a list of hobbies. Here are the existing categories:\\n\"\n",
    "    \n",
    "    categories_list = \"\\n\".join(all_categories)\n",
    "    special_categories = \"\"\"\n",
    "    Special categories for handling noise in the data:\n",
    "    - ei mainintaa: Use this category only if the entity is blank, says \"not mentioned\" or \"ei mainintaa\" or anything similar.\n",
    "    - työ/ammatti: Use this category only if the entity clearly describes a job or profession and could not be counted as a hobby.\n",
    "    - organisaatiot: Use this category only if the entity specifically names an organization. For example Marttayhdistys, or Karjalaisseura.\n",
    "    \"\"\"\n",
    "    unmatched_instruction = \"\"\"\\n\n",
    "    These hobbies are previously unmatched or from too specific categories, \n",
    "    please review carefully and be general in your sorting. \n",
    "    Note that new categories might have been created where these entities can fit.\n",
    "    \"\"\"\n",
    "\n",
    "    new_category_instructions = \"\"\"\n",
    "    Categorize each hobby into one of the existing categories. \n",
    "    If a hobby does not fit into any of these categories, you can create a new category by stating: new category, [category name].\n",
    "    Try to create general categories and avoid creating too specific categories.\n",
    "    \"\"\"\n",
    "    format_instructions = \"Format the response as: hobby: category\"\n",
    "\n",
    "    indexed_hobbies = [f\"{i+1}. {hobby}\" for i, hobby in enumerate(hobbies_batch)]\n",
    "    hobbies_to_categorize = \"\\n\".join(indexed_hobbies)\n",
    "\n",
    "    full_prompt = (introduction + categories_list + special_categories + \n",
    "                   (unmatched_instruction if from_unmatched else \"\") + \n",
    "                   new_category_instructions + format_instructions + \n",
    "                   \"\\nCategorize the following hobbies:\\n\" + hobbies_to_categorize)\n",
    "\n",
    "    print(\"Full prompt being sent to the API:\")\n",
    "    print(full_prompt)\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": full_prompt}]\n",
    "    )\n",
    "\n",
    "    # Get the current time\n",
    "    now = datetime.datetime.now()\n",
    "    date_time = now.strftime(\"%d%m%H%M\")  # Format as day, month, hour, minute\n",
    "\n",
    "    # Save the raw response to a file in the raw_output directory\n",
    "    batch_index = hobbies_batch[0]  # Using the first hobby's index as the file identifier\n",
    "    raw_output_path = os.path.join(raw_output_dir, f'raw_output_batch_{batch_index}_{date_time}.json')\n",
    "    with open(raw_output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(response, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    return response, hobbies_batch\n",
    "\n",
    "\n",
    "def process_categorized_data(response, original_hobbies):\n",
    "    new_unmatched_hobbies = []\n",
    "    for choice in response['choices']:\n",
    "        categorized_data = choice['message']['content']\n",
    "        for line in categorized_data.split(\"\\n\"):\n",
    "            if \": \" in line:\n",
    "                index, rest = line.split(\". \", 1)\n",
    "                hobby, category = rest.split(\": \", 1)\n",
    "                original_hobby = original_hobbies[int(index) - 1].strip()\n",
    "                save_hobby(original_hobby, category.strip())\n",
    "            else:\n",
    "                new_unmatched_hobbies.append(original_hobbies[int(index) - 1].strip())\n",
    "    unmatched_hobbies[:] = new_unmatched_hobbies  # Update unmatched list\n",
    "\n",
    "def run_categorization():\n",
    "    load_data()  # Ensure data is loaded at the beginning of the session\n",
    "    batch_size = 50\n",
    "    num_batches = math.ceil(len(hobbies) / batch_size)\n",
    "    for i in range(num_batches):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = min((i + 1) * batch_size, len(hobbies))\n",
    "        hobbies_batch = hobbies[batch_start:batch_end]\n",
    "        print(f\"Processing batch {i+1}/{num_batches}\")\n",
    "        response, original_hobbies = categorize_hobby_batch(hobbies_batch, from_unmatched=False)\n",
    "        process_categorized_data(response, original_hobbies)\n",
    "        print(f\"Batch {i+1} processed\")\n",
    "\n",
    "load_data()  # Load all data at startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59464d64-b52d-43fb-85df-fb6bec0c95a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "# Delete variables\n",
    "del model\n",
    "del tokenizer\n",
    "del generation_pipeline\n",
    "\n",
    "# Collect garbage\n",
    "gc.collect()\n",
    "\n",
    "# Empty the cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080839aa-88a8-47f4-85b3-185468e034d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import datetime\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "\n",
    "# Ensure raw output directory exists\n",
    "raw_output_dir = 'data/raw_output'\n",
    "os.makedirs(raw_output_dir, exist_ok=True)\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "print(model_id)\n",
    "shared_dir = \"/scratch/project_462000642/joonatan/shared_models\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, cache_dir=shared_dir)\n",
    "\n",
    "# Load the model with Flash Attention 2\n",
    "with torch.device(\"cuda\"):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        cache_dir=shared_dir,\n",
    "        torch_dtype=torch.float16,\n",
    "        use_flash_attention_2=True,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "# Initialize the text generation pipeline\n",
    "generation_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c04af-be11-4f4c-a49a-bf5d4029bbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(full_prompt):\n",
    "    # Configuration settings for different generation scenarios\n",
    "    configs = [\n",
    "        {\"do_sample\": False, \"num_beams\": 1, \"temperature\": 0.3, \"top_k\": 50, \"top_p\": 0.1, \"max_new_tokens\": 1500},\n",
    "        {\"do_sample\": True, \"num_beams\": 1, \"temperature\": 0.3, \"top_k\": 50, \"top_p\": 0.1, \"max_new_tokens\": 1500},\n",
    "        {\"do_sample\": True, \"num_beams\": 1, \"temperature\": 0.3, \"top_k\": 50, \"top_p\": 0.8, \"max_new_tokens\": 1500},\n",
    "    ]\n",
    "\n",
    "    # Select configuration - example using the first configuration\n",
    "    config = configs[0]\n",
    "\n",
    "    # Prepare messages in the required format for the model\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant who categorizes hobbies.\"},\n",
    "        {\"role\": \"user\", \"content\": full_prompt}\n",
    "    ]\n",
    "\n",
    "    # Generate text using the selected configuration\n",
    "    outputs = generation_pipeline(messages, \n",
    "                                  max_new_tokens=config['max_new_tokens'], \n",
    "                                  num_beams=config['num_beams'], \n",
    "                                  do_sample=config['do_sample'],\n",
    "                                  temperature=config['temperature'], \n",
    "                                  top_k=config['top_k'], \n",
    "                                  top_p=config['top_p'])\n",
    "\n",
    "    # Assuming the outputs contain the assistant's response, directly returned by the model\n",
    "    # Adjust according to the model's actual output format.\n",
    "    assistant_response = outputs[0][\"generated_text\"][-1]\n",
    "\n",
    "#    print(outputs)  # Optional: Print output for debugging\n",
    "    return assistant_response\n",
    "\n",
    "# Example usage\n",
    "full_prompt = \"I enjoy swimming, reading, and playing chess. How would you categorize these hobbies?\"\n",
    "assistant_reply = generate_text(full_prompt)\n",
    "print(assistant_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e4de56-ef13-483a-9cb6-cee4644a818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(full_prompt):\n",
    "    # Predefined response string\n",
    "    predefined_response = \"\"\"1. käsityöt: käsityöt \n",
    "    2. kalastus: kalastus \n",
    "    3. kirjallisuus: kirjallisuus \n",
    "    4. puutarhanhoito: uusi kategoria, puutarha \n",
    "    5. lukeminen: kirjallisuus \n",
    "    6. metsästys: metsästys \n",
    "    7. hiihto: yksilöurheilu \n",
    "    8. ulkoilu: uusi kategoria, luonnon havainnointi \n",
    "    9. urheilu: ryhmäurheilu \n",
    "    10. käsitöitä: käsityöt \n",
    "    11. retkeily: uusi kategoria, luonnon havainnointi \n",
    "    12. musiikki: musiikki \n",
    "    13. voimistelu: yksilöurheilu \n",
    "    14. matkailu: uusi kategoria, matkailu \n",
    "    15. kuorolaulu: musiikki \n",
    "    16. kodinhoito: tässä tarvitaan uusi uusi kategoria, kodinhoito \n",
    "    17. käsitöiden tekeminen: käsityöt \n",
    "    18. laulu: musiikki \n",
    "    19. uinti: yksilöurheilu \n",
    "    20. autoilu: uusi kategoria, autoilu \n",
    "    21. karjanhoito: tämä ei sovi minnekkään joten uusi kategoria, karjanhoito \n",
    "    22. puutarhatyöt: puutarha \n",
    "    \"\"\"\n",
    "    return {\"content\": predefined_response}\n",
    "\n",
    "# Example usage\n",
    "full_prompt = \"I enjoy swimming, reading, and playing chess. How would you categorize these hobbies?\"\n",
    "assistant_reply = generate_text(full_prompt)\n",
    "print(assistant_reply[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe721d2-47bd-4fd9-b178-7f4065820621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# Ensure raw output directory exists\n",
    "raw_output_dir = 'data/tests/raw_output'\n",
    "os.makedirs(raw_output_dir, exist_ok=True)\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Read the JSON file\n",
    "with open('data/tests/hobbiesforapi.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "hobbies = list(data['HobbiesCount'].keys())\n",
    "\n",
    "# Global variables\n",
    "all_categories = [\n",
    "    \"käsityöt\", \"yksilöurheilu\", \"kirjallisuus\", \"ryhmäurheilu\", \"musiikki\", \"valokuvaus\",\n",
    "    \"kalastus\", \"metsästys\", \"vapaaehtoistoiminta\", \"pelit\", \"ei mainintaa\", \"työ/ammatti\", \"organisaatiot\"\n",
    "]\n",
    "categories = {}\n",
    "unmatched_hobbies = []\n",
    "\n",
    "def load_data():\n",
    "    global categories, unmatched_hobbies, all_categories\n",
    "    \n",
    "    print(\"Starting data loading process...\")\n",
    "    \n",
    "    # Load categories\n",
    "    try:\n",
    "        with open('data/tests/categorized_hobbies_testing.json', 'r', encoding='utf-8') as f:\n",
    "            categories = json.load(f)\n",
    "        print(f\"Successfully loaded categorized hobbies from file.\")\n",
    "        print(f\"Number of categories: {len(categories)}\")\n",
    "        \n",
    "        # Update all_categories with loaded categories\n",
    "        all_categories = list(set(all_categories + list(categories.keys())))\n",
    "        \n",
    "        for category, hobbies in categories.items():\n",
    "            print(f\"  - {category}: {len(hobbies)} hobbies\")\n",
    "        print(f\"Total categorized hobbies: {sum(len(hobbies) for hobbies in categories.values())}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"No existing category data found. Initializing with empty categories.\")\n",
    "        categories = {category: [] for category in all_categories}\n",
    "        print(f\"Initialized {len(categories)} empty categories.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error decoding categorized hobbies JSON. File may be corrupted.\")\n",
    "        categories = {category: [] for category in all_categories}\n",
    "    \n",
    "    # Load unmatched hobbies\n",
    "    try:\n",
    "        with open('data/tests/unmatched_hobbies_testing.json', 'r', encoding='utf-8') as f:\n",
    "            unmatched_hobbies = json.load(f)\n",
    "        print(f\"Successfully loaded unmatched hobbies from file.\")\n",
    "        print(f\"Number of unmatched hobbies: {len(unmatched_hobbies)}\")\n",
    "        if unmatched_hobbies:\n",
    "            print(\"First 5 unmatched hobbies:\")\n",
    "            for hobby in unmatched_hobbies[:5]:\n",
    "                print(f\"  - {hobby}\")\n",
    "            if len(unmatched_hobbies) > 5:\n",
    "                print(f\"  ... and {len(unmatched_hobbies) - 5} more\")\n",
    "    except FileNotFoundError:\n",
    "        unmatched_hobbies = []\n",
    "        print(\"No unmatched hobbies data found. Starting with an empty list.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error decoding unmatched hobbies JSON. File may be corrupted.\")\n",
    "        unmatched_hobbies = []\n",
    "    \n",
    "    print(\"\\nData loading summary:\")\n",
    "    print(f\"Total categories: {len(all_categories)}\")\n",
    "    print(f\"Categories: {', '.join(all_categories)}\")\n",
    "    print(f\"Total categorized hobbies: {sum(len(hobbies) for hobbies in categories.values())}\")\n",
    "    print(f\"Total unmatched hobbies: {len(unmatched_hobbies)}\")\n",
    "    print(\"Data loading process complete.\")\n",
    "\n",
    "def save_data():\n",
    "    with open('data/tests/categorized_hobbies_testing.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(categories, f, ensure_ascii=False, indent=4)\n",
    "    with open('data/tests/unmatched_hobbies_testing.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(unmatched_hobbies, f, ensure_ascii=False, indent=4)\n",
    "    print(\"Data saved to files.\")\n",
    "\n",
    "def save_hobby(hobby, category_info):\n",
    "    global all_categories, categories, unmatched_hobbies\n",
    "    \n",
    "    # List of phrases that indicate a new category\n",
    "    new_category_indicators = [\"uusi kategoria,\", \"new category,\"]\n",
    "    \n",
    "    # Remove any leading/trailing whitespace\n",
    "    category_info = category_info.strip()\n",
    "    \n",
    "    # Check if this is a new category\n",
    "    is_new_category = any(indicator in category_info.lower() for indicator in new_category_indicators)\n",
    "    \n",
    "    if is_new_category:\n",
    "        # Extract the new category name\n",
    "        for indicator in new_category_indicators:\n",
    "            if indicator in category_info.lower():\n",
    "                _, category = category_info.lower().split(indicator, 1)\n",
    "                category = category.strip()\n",
    "                break\n",
    "        \n",
    "        # Create the new category if it doesn't exist\n",
    "        if category not in categories:\n",
    "            categories[category] = []\n",
    "            all_categories.append(category)\n",
    "    else:\n",
    "        # Use the provided category directly\n",
    "        category = category_info\n",
    "        \n",
    "        # If the category doesn't exist, add it to unmatched_hobbies\n",
    "        if category not in categories:\n",
    "            unmatched_hobbies.append(hobby)\n",
    "            return None  # Return None to indicate the hobby wasn't categorized\n",
    "    \n",
    "    # Add the hobby to the appropriate category\n",
    "    categories[category].append(hobby)\n",
    "    \n",
    "    # Remove the hobby from unmatched_hobbies if it's there\n",
    "    if hobby in unmatched_hobbies:\n",
    "        unmatched_hobbies.remove(hobby)\n",
    "    \n",
    "    return category  # Return the category name\n",
    "\n",
    "def destroy_categories(category_names):\n",
    "    global all_categories  # Ensure we are modifying the global variable\n",
    "    # Load the current state of data\n",
    "    load_data()\n",
    "    \n",
    "    for category_name in category_names:\n",
    "        if category_name in categories:\n",
    "            destroyed_hobbies = categories.pop(category_name)\n",
    "            unmatched_hobbies.extend(destroyed_hobbies)\n",
    "            all_categories = [cat for cat in all_categories if cat != category_name]  # Rebuild all_categories\n",
    "            print(f\"Category '{category_name}' has been destroyed. Its hobbies have been moved to unmatched hobbies.\")\n",
    "        else:\n",
    "            print(f\"Category '{category_name}' not found.\")\n",
    "    \n",
    "    save_data()  # Save data only once after all categories have been processed\n",
    "\n",
    "\n",
    "\n",
    "def categorize_hobby_batch(hobbies_batch, from_unmatched=False):\n",
    "    global all_categories \n",
    "\n",
    "    introduction = \"Olet avulias assistentti, jonka tehtävänä on luokitella lista harrastuksia annettuihin kategorioihin.\"\n",
    "\n",
    "    # List of hobbies to categorize\n",
    "    indexed_hobbies = [f\"{i+1}. {hobby}\" for i, hobby in enumerate(hobbies_batch)]\n",
    "    hobbies_to_categorize = \"Luokiteltavat harrastukset:\\n\" + \"\\n\".join(indexed_hobbies)\n",
    "\n",
    "    # List of categories\n",
    "    categories_list = \"Käytettävissä olevat kategoriat:\\n\" + \"\\n\".join(all_categories)\n",
    "\n",
    "    special_categories = \"\"\"\n",
    "    Erityiskategoriat datan kohinan käsittelyyn:\n",
    "    - ei mainintaa: Käytä tätä kategoriaa vain, jos kohde on tyhjä, siinä lukee \"ei mainintaa\" tai vastaavaa.\n",
    "    - työ/ammatti: Käytä tätä kategoriaa vain, jos kohde selvästi kuvaa työtä tai ammattia eikä sitä voida laskea harrastukseksi.\n",
    "    - organisaatiot: Käytä tätä kategoriaa vain, jos kohde nimeää erityisesti jonkin organisaation. Esimerkiksi Marttayhdistys tai Karjalaisseura.\n",
    "    \"\"\"\n",
    "\n",
    "    format_instructions = \"\"\"\n",
    "    TÄRKEÄÄ: Noudata tarkasti seuraavaa muotoilua vastauksessasi:\n",
    "    indeksi. harrastus: kategoria\n",
    "\n",
    "    Jos luot uuden kategorian, käytä muotoa:\n",
    "    indeksi. harrastus: uusi kategoria, kategorian_nimi\n",
    "\n",
    "    Jokainen vastaus TÄYTYY olla omalla rivillään.\n",
    "    ÄLÄ lisää selityksiä tai ylimääräistä tekstiä vastauksiin.\n",
    "    Käytä vain annettuja kategorioita tai luo uusi kategoria tarvittaessa.\n",
    "\n",
    "    Esimerkkejä oikeasta muotoilusta:\n",
    "    1. uiminen: yksilöurheilu\n",
    "    2. lintu bongaus: uusi kategoria, luonnon havainnointi\n",
    "    3. ompelu: käsityöt\n",
    "    \"\"\"\n",
    "\n",
    "    new_category_instructions = \"\"\"\n",
    "    Jos harrastus ei sovi mihinkään olemassa olevaan kategoriaan, voit luoda uuden kategorian seuraavien ohjeiden mukaisesti:\n",
    "    1. Käytä tarkkaa ilmausta \"uusi kategoria, \" (pilkku ja välilyönti mukaan lukien) ja sen jälkeen uuden kategorian nimi.\n",
    "    2. Uuden kategorian nimen tulee olla yleisluontoinen eikä liian tarkka.\n",
    "    3. Luotuasi uuden kategorian, käytä sitä nykyiselle harrastukselle ja kaikille seuraaville harrastuksille, jotka sopivat siihen.\n",
    "    4. Älä luo alakategorioita tai käytä kaksoispisteitä uusien kategorioiden nimissä.\n",
    "    \"\"\"\n",
    "\n",
    "    unmatched_instruction = \"\"\"\\n\n",
    "    Nämä harrastukset ovat aiemmin luokittelemattomia tai liian tarkasti määritellyistä kategorioista, \n",
    "    tarkastele ne huolellisesti ja ole yleisluontoinen lajittelussasi. \n",
    "    Huomaa, että uusia kategorioita on saatettu luoda, joihin nämä kohteet voivat sopia.\n",
    "    \"\"\" if from_unmatched else \"\"\n",
    "\n",
    "    full_prompt = (\n",
    "        introduction + \"\\n\\n\" +\n",
    "        hobbies_to_categorize + \"\\n\\n\" +\n",
    "        special_categories + \"\\n\\n\" +\n",
    "        categories_list + \"\\n\\n\" +\n",
    "        new_category_instructions + \"\\n\\n\" +\n",
    "        unmatched_instruction + \"\\n\\n\" +\n",
    "        format_instructions + \"\\n\\n\" +\n",
    "        \"Luokittele nyt annetut harrastukset:\"\n",
    "    )\n",
    "\n",
    "    response_text = generate_text(full_prompt)\n",
    "\n",
    "    # Get the current time\n",
    "    now = datetime.datetime.now()\n",
    "    date_time = now.strftime(\"%d%m%H%M\")  # Format as day, month, hour, minute\n",
    "\n",
    "    # Save the raw response to a file in the raw_output directory\n",
    "    batch_index = hobbies_batch[0]  # Using the first hobby's index as the file identifier\n",
    "    raw_output_path = os.path.join(raw_output_dir, f'raw_output_batch_{batch_index}_{date_time}.json')\n",
    "    with open(raw_output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(response_text, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    return response_text, hobbies_batch\n",
    "\n",
    "def process_categorized_data(response, original_hobbies):\n",
    "    newly_categorized = []\n",
    "    categorized_data = response.get('content', '')\n",
    "    lines = categorized_data.split(\"\\n\")\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            if \": \" in line and \". \" in line:\n",
    "                index_part, category_info = line.split(\". \", 1)\n",
    "                index = int(index_part) - 1\n",
    "                \n",
    "                if 0 <= index < len(original_hobbies):\n",
    "                    original_hobby = original_hobbies[index].strip()\n",
    "                    category = save_hobby(original_hobby, category_info.split(\": \", 1)[1])\n",
    "                    if category is not None:\n",
    "                        newly_categorized.append(original_hobby)\n",
    "                else:\n",
    "                    print(f\"Index out of range: {index}\")\n",
    "            else:\n",
    "                print(f\"Skipping line due to incorrect format: {line}\")\n",
    "        except (ValueError, IndexError) as e:\n",
    "            print(f\"Error processing line: {line}\")\n",
    "            print(f\"Exception: {e}\")\n",
    "\n",
    "    save_data()  # Save categorized data after processing the batch\n",
    "    return newly_categorized\n",
    "\n",
    "\n",
    "def recategorize_unmatched_hobbies():\n",
    "    load_data()\n",
    "    print(f\"Loaded {len(unmatched_hobbies)} unmatched hobbies\")\n",
    "    \n",
    "    # Create a copy of unmatched hobbies to process\n",
    "    hobbies_to_process = unmatched_hobbies.copy()\n",
    "    \n",
    "    batch_size = 50\n",
    "    num_batches = math.ceil(len(hobbies_to_process) / batch_size)\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = min((i + 1) * batch_size, len(hobbies_to_process))\n",
    "        hobbies_batch = hobbies_to_process[batch_start:batch_end]\n",
    "        \n",
    "        print(f\"Processing batch {i+1}/{num_batches}\")\n",
    "        \n",
    "        if not hobbies_batch:\n",
    "            print(\"Empty batch encountered. Stopping process.\")\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            response, original_hobbies = categorize_hobby_batch(hobbies_batch, from_unmatched=True)\n",
    "            newly_categorized = process_categorized_data(response, original_hobbies)\n",
    "            \n",
    "            # Remove categorized hobbies from the unmatched_hobbies list\n",
    "            unmatched_hobbies[:] = [h for h in unmatched_hobbies if h not in newly_categorized]\n",
    "            \n",
    "            # Save updated unmatched_hobbies to JSON after each batch\n",
    "            save_unmatched_hobbies()\n",
    "            \n",
    "            print(f\"Batch {i+1} processed. Categorized {len(newly_categorized)} hobbies.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {i+1}: {str(e)}\")\n",
    "        \n",
    "        print(f\"Remaining unmatched hobbies: {len(unmatched_hobbies)}\")\n",
    "    \n",
    "    print(\"Recategorization process complete\")\n",
    "    print(f\"Final unmatched hobbies count: {len(unmatched_hobbies)}\")\n",
    "\n",
    "def save_unmatched_hobbies():\n",
    "    with open('data/tests/unmatched_hobbies_testing.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(unmatched_hobbies, f, ensure_ascii=False, indent=4)\n",
    "    print(\"Unmatched hobbies saved to file.\")\n",
    "\n",
    "def run_categorization():\n",
    "    load_data()  # Ensure data is loaded at the beginning of the session\n",
    "    batch_size = 300\n",
    "    num_batches = math.ceil(len(hobbies) / batch_size)\n",
    "    for i in range(num_batches):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = min((i + 1) * batch_size, len(hobbies))\n",
    "        hobbies_batch = hobbies[batch_start:batch_end]\n",
    "        print(f\"Processing batch {i+1}/{num_batches}\")\n",
    "        response, original_hobbies = categorize_hobby_batch(hobbies_batch, from_unmatched=False)\n",
    "        process_categorized_data(response, original_hobbies)\n",
    "        print(f\"Batch {i+1} processed\")\n",
    "\n",
    "load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1d2d0b-4c86-4da1-8d80-420b44659ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_categorization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8082e615-e49f-421c-a098-3bebdac357bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "recategorize_unmatched_hobbies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7717db7a-906d-4c8f-9a15-03d1022272f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "destroy_categories(['yleisurheilu','marttatyö'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ec2fbc-63a5-4c44-a7bb-5f3381903119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "\n",
    "import json\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(data, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "def get_all_categorized_hobbies(categorized_hobbies):\n",
    "    return set(hobby for category in categorized_hobbies.values() for hobby in category)\n",
    "\n",
    "def main():\n",
    "    # Load the original hobbies\n",
    "    data = load_json('data/combinedHowManyHobbies2.json')\n",
    "    original_hobbies = set(data['HobbiesCount'].keys())\n",
    "\n",
    "    # Load the categorized hobbies\n",
    "    categorized_hobbies = load_json('data/categorized_hobbies_flash.json')\n",
    "    all_categorized_hobbies = get_all_categorized_hobbies(categorized_hobbies)\n",
    "\n",
    "    # Find unmatched hobbies\n",
    "    unmatched_hobbies = list(original_hobbies - all_categorized_hobbies)\n",
    "\n",
    "    # Save unmatched hobbies directly to JSON root\n",
    "    save_json(unmatched_hobbies, 'data/unmatched_hobbies_flash.json')\n",
    "\n",
    "    print(f\"Found {len(unmatched_hobbies)} unmatched hobbies. Saved to data/unmatched_hobbies_testing.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec23eb0d-f751-460f-a1a3-76b8a286a3a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Path to the JSON file\n",
    "file_path = 'data/categorized_hobbies_blind.json'\n",
    "\n",
    "# Read the JSON file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Print all category names\n",
    "for category in data.keys():\n",
    "    print(category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ccf970-f41d-4eb7-98a0-cd736f9e3209",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def analyze_categories(files):\n",
    "    all_categories = set()\n",
    "    category_counts = Counter()\n",
    "    file_data = {}\n",
    "\n",
    "    for file in files:\n",
    "        data = load_json(file)\n",
    "        categories = set(data.keys())\n",
    "        all_categories.update(categories)\n",
    "        category_counts.update(categories)\n",
    "        file_data[file] = data\n",
    "\n",
    "    # Convert set to sorted list for consistent ordering\n",
    "    all_categories_list = sorted(all_categories)\n",
    "\n",
    "    df = pd.DataFrame(index=all_categories_list, columns=files)\n",
    "    for file in files:\n",
    "        df[file] = df.index.isin(file_data[file].keys()).astype(int)\n",
    "\n",
    "    df['total'] = df.sum(axis=1)\n",
    "    df = df.sort_values('total', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.heatmap(df[files], cmap='YlOrRd', cbar_kws={'label': 'Present in file'})\n",
    "    plt.title('Category Presence Across Files')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('category_heatmap.png')\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Category presence across files saved as 'category_heatmap.png'\")\n",
    "    print(\"\\nCategory frequency:\")\n",
    "    print(df['total'].to_string())\n",
    "\n",
    "\n",
    "    # Calculate percentage of files each category appears in\n",
    "    df['percentage'] = (df['total'] / len(files)) * 100\n",
    "    \n",
    "    print(\"\\nCategories present in all files:\")\n",
    "    print(df[df['percentage'] == 100].index.tolist())\n",
    "\n",
    "    print(\"\\nCategories present in only one file:\")\n",
    "    print(df[df['total'] == 1].index.tolist())\n",
    "\n",
    "    # Visualize category distribution\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    df['percentage'].hist(bins=len(files))\n",
    "    plt.title('Distribution of Category Presence Across Files')\n",
    "    plt.xlabel('Percentage of Files')\n",
    "    plt.ylabel('Number of Categories')\n",
    "    plt.savefig('category_distribution.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def analyze_entity_cooccurrence(files):\n",
    "    all_entities = set()\n",
    "    entity_categories = {}\n",
    "    \n",
    "    for file in files:\n",
    "        data = load_json(file)\n",
    "        for category, entities in data.items():\n",
    "            all_entities.update(entities)\n",
    "            for entity in entities:\n",
    "                if entity not in entity_categories:\n",
    "                    entity_categories[entity] = set()\n",
    "                entity_categories[entity].add(category)\n",
    "\n",
    "    # Convert all entities to lowercase to avoid warnings\n",
    "    all_entities = {entity.lower() for entity in all_entities}\n",
    "\n",
    "    vectorizer = CountVectorizer(vocabulary=all_entities, lowercase=True)\n",
    "    entity_vectors = []\n",
    "\n",
    "    for file in files:\n",
    "        data = load_json(file)\n",
    "        doc = ' '.join([' '.join(entities).lower() for entities in data.values()])\n",
    "        entity_vectors.append(vectorizer.fit_transform([doc]).toarray()[0])\n",
    "\n",
    "    try:\n",
    "        # Use get_feature_names_out() for newer scikit-learn versions\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "    except AttributeError:\n",
    "        # Fallback for older versions\n",
    "        feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "    entity_matrix = pd.DataFrame(entity_vectors, columns=feature_names, index=files)\n",
    "    \n",
    "    # Clustering\n",
    "    kmeans = KMeans(n_clusters=min(10, len(entity_matrix.columns)), random_state=42)\n",
    "    clusters = kmeans.fit_predict(entity_matrix.T)\n",
    "    \n",
    "    # Dimensionality reduction for visualization\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    entity_2d = tsne.fit_transform(entity_matrix.T)\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    scatter = plt.scatter(entity_2d[:, 0], entity_2d[:, 1], c=clusters, cmap='viridis', alpha=0.7)\n",
    "    plt.colorbar(scatter, label='Cluster')\n",
    "    plt.title('Entity Clustering')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('entity_clusters.png')\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Entity clustering visualization saved as 'entity_clusters.png'\")\n",
    "\n",
    "    # Find differing clusters\n",
    "    cluster_diffs = {}\n",
    "    for i, file1 in enumerate(files):\n",
    "        for j, file2 in enumerate(files[i+1:], start=i+1):\n",
    "            diff_entities = set(entity_matrix.columns[entity_matrix.iloc[i] != entity_matrix.iloc[j]])\n",
    "            if diff_entities:\n",
    "                cluster_diffs[(file1, file2)] = diff_entities\n",
    "\n",
    "    print(\"\\nDiffering entities between files:\")\n",
    "    for (file1, file2), diff_entities in cluster_diffs.items():\n",
    "        print(f\"\\n{file1} vs {file2}:\")\n",
    "        print(\", \".join(sorted(diff_entities)[:20]))  # Print first 20 differing entities\n",
    "\n",
    "    # Additional analysis: Most common entities across all files\n",
    "    entity_sums = entity_matrix.sum()\n",
    "    print(\"\\nTop 20 most common entities across all files:\")\n",
    "    print(entity_sums.nlargest(20).to_string())\n",
    "\n",
    "    # Visualize entity frequency distribution\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    entity_sums.hist(bins=50)\n",
    "    plt.title('Distribution of Entity Frequency Across Files')\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('Number of Entities')\n",
    "    plt.savefig('entity_frequency_distribution.png')\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Entity frequency distribution visualization saved as 'entity_frequency_distribution.png'\")\n",
    "\n",
    "    # Find differing clusters\n",
    "    cluster_diffs = {}\n",
    "    for i, file1 in enumerate(files):\n",
    "        for j, file2 in enumerate(files[i+1:], start=i+1):\n",
    "            diff_entities = set(entity_matrix.iloc[i].index[entity_matrix.iloc[i] != entity_matrix.iloc[j]])\n",
    "            if diff_entities:\n",
    "                cluster_diffs[(file1, file2)] = diff_entities\n",
    "\n",
    "    print(\"\\nDiffering entities between files:\")\n",
    "    for (file1, file2), diff_entities in cluster_diffs.items():\n",
    "        print(f\"\\n{file1} vs {file2}:\")\n",
    "        print(\", \".join(sorted(diff_entities)[:20]))  # Print first 20 differing entities\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    files = [\n",
    "        'data/categorized_hobbies_blind_completed1.json',\n",
    "        'data/categorized_hobbies_finnish_completed1.json',\n",
    "        'data/categorized_hobbies_completed1.json',\n",
    "        'data/categorized_hobbies_flash_1_completed.json'\n",
    "    ]\n",
    "    \n",
    "    print(\"Analyzing categories...\")\n",
    "    analyze_categories(files)\n",
    "    \n",
    "    print(\"\\nAnalyzing entity co-occurrence and clustering...\")\n",
    "    analyze_entity_cooccurrence(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cece3847-cc4d-4c43-ae72-565e99b64682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
